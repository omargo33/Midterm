[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Aprendizaje Supervisado",
    "section": "",
    "text": "Autor: Omar Velez - omar.velez@yachaytech.edu.ec"
  },
  {
    "objectID": "index.html#obtención-de-la-data",
    "href": "index.html#obtención-de-la-data",
    "title": "Aprendizaje Supervisado",
    "section": "Obtención de la data:",
    "text": "Obtención de la data:\nPara la obtención de la DataFrame se obtiene la predicción de deserción escolar de la: Irvine, Universidad de California (UCI) Ver\nEl DataFrame original en su target tiene los siguientes estados: ‘Dropout’, ‘Enrolled’, ‘Graduate’. Y hay que reducirlos a Enrolled y Graduate para podemos usar como 0 y 1 respectivamente.\n\nDesarrollo\n\nSe instala la librería del DataFrame\n\n\nCode\n!pip install ucimlrepo\n\n\nRequirement already satisfied: ucimlrepo in /home/ovelez/Documentos/cursos/Maestria/modulo1/ejerciciosPhyton/.venv/lib/python3.12/site-packages (0.0.7)\nRequirement already satisfied: pandas&gt;=1.0.0 in /home/ovelez/Documentos/cursos/Maestria/modulo1/ejerciciosPhyton/.venv/lib/python3.12/site-packages (from ucimlrepo) (2.3.2)\nRequirement already satisfied: certifi&gt;=2020.12.5 in /home/ovelez/Documentos/cursos/Maestria/modulo1/ejerciciosPhyton/.venv/lib/python3.12/site-packages (from ucimlrepo) (2025.8.3)\nRequirement already satisfied: numpy&gt;=1.26.0 in /home/ovelez/Documentos/cursos/Maestria/modulo1/ejerciciosPhyton/.venv/lib/python3.12/site-packages (from pandas&gt;=1.0.0-&gt;ucimlrepo) (2.3.3)\nRequirement already satisfied: python-dateutil&gt;=2.8.2 in /home/ovelez/Documentos/cursos/Maestria/modulo1/ejerciciosPhyton/.venv/lib/python3.12/site-packages (from pandas&gt;=1.0.0-&gt;ucimlrepo) (2.9.0.post0)\nRequirement already satisfied: pytz&gt;=2020.1 in /home/ovelez/Documentos/cursos/Maestria/modulo1/ejerciciosPhyton/.venv/lib/python3.12/site-packages (from pandas&gt;=1.0.0-&gt;ucimlrepo) (2025.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in /home/ovelez/Documentos/cursos/Maestria/modulo1/ejerciciosPhyton/.venv/lib/python3.12/site-packages (from pandas&gt;=1.0.0-&gt;ucimlrepo) (2025.2)\nRequirement already satisfied: six&gt;=1.5 in /home/ovelez/Documentos/cursos/Maestria/modulo1/ejerciciosPhyton/.venv/lib/python3.12/site-packages (from python-dateutil&gt;=2.8.2-&gt;pandas&gt;=1.0.0-&gt;ucimlrepo) (1.17.0)\n\n\n\n\nVálido si está correctamente instalada la librería\n\n\nCode\nimport ucimlrepo\nprint(\"ucimlrepo instalado correctamente\")\n\n\nucimlrepo instalado correctamente\n\n\n\n\nSe obtiene el dataFrame desde la url de la UCI\n\n\nCode\nfrom ucimlrepo import fetch_ucirepo \n  \n# fetch dataset 697\npredict_students_dropout_and_academic_success = fetch_ucirepo(id=697) \n  \n# data (as pandas dataframes) \nX = predict_students_dropout_and_academic_success.data.features \ny = predict_students_dropout_and_academic_success.data.targets \n  \n# metadata \nprint(predict_students_dropout_and_academic_success.metadata) \n  \n# variable information \nprint(predict_students_dropout_and_academic_success.variables) \n\n\n{'uci_id': 697, 'name': \"Predict Students' Dropout and Academic Success\", 'repository_url': 'https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success', 'data_url': 'https://archive.ics.uci.edu/static/public/697/data.csv', 'abstract': \"A dataset created from a higher education institution (acquired from several disjoint databases) related to students enrolled in different undergraduate degrees, such as agronomy, design, education, nursing, journalism, management, social service, and technologies.\\nThe dataset includes information known at the time of student enrollment (academic path, demographics, and social-economic factors) and the students' academic performance at the end of the first and second semesters. \\nThe data is used to build classification models to predict students' dropout and academic sucess. The problem is formulated as a three category classification task, in which there is a strong imbalance towards one of the classes.\", 'area': 'Social Science', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 4424, 'num_features': 36, 'feature_types': ['Real', 'Categorical', 'Integer'], 'demographics': ['Marital Status', 'Education Level', 'Nationality', 'Occupation', 'Gender', 'Age'], 'target_col': ['Target'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2021, 'last_updated': 'Mon Feb 26 2024', 'dataset_doi': '10.24432/C5MC89', 'creators': ['Valentim Realinho', 'Mónica Vieira Martins', 'Jorge Machado', 'Luís Baptista'], 'intro_paper': {'ID': 99, 'type': 'NATIVE', 'title': \"Early prediction of student's performance in higher education: a case study\", 'authors': 'Mónica V. Martins, Daniel Tolledo, Jorge Machado, Luís M. T. Baptista, and Valentim Realinho', 'venue': 'Trends and Applications in Information Systems and Technologies', 'year': 2021, 'journal': 'Advances in Intelligent Systems and Computing series', 'DOI': 'http://www.doi.org/10.1007/978-3-030-72657-7_16', 'URL': 'http://www.worldcist.org/2021/', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': None, 'purpose': 'The dataset was created in a project that aims to contribute to the reduction of academic dropout and failure in higher education, by using machine learning techniques to identify students at risk at an early stage of their academic path, so that strategies to support them can be put into place. \\n\\nThe dataset includes information known at the time of student enrollment – academic path, demographics, and social-economic factors. \\n\\nThe problem is formulated as a three category classification task (dropout, enrolled, and graduate) at the end of the normal duration of the course. \\n', 'funded_by': 'This dataset is supported by program SATDAP - Capacitação da Administração Pública under grant POCI-05-5762-FSE-000191, Portugal.', 'instances_represent': 'Each instance is a student', 'recommended_data_splits': 'The dataset was used, in our project, with a data split of 80% for training and 20% for test.', 'sensitive_data': None, 'preprocessing_description': 'We performed a rigorous data preprocessing to handle data from anomalies, unexplainable outliers, and missing values.', 'variable_info': None, 'citation': 'If you use this dataset in experiments for a scientific publication, please kindly cite our paper: \\nM.V.Martins, D. Tolledo, J. Machado, L. M.T. Baptista, V.Realinho. (2021) \"Early prediction of student’s performance in higher education: a case study\" Trends and Applications in Information Systems and Technologies, vol.1, in Advances in Intelligent Systems and Computing series. Springer. DOI: 10.1007/978-3-030-72657-7_16'}}\n                                              name     role         type  \\\n0                                   Marital Status  Feature      Integer   \n1                                 Application mode  Feature      Integer   \n2                                Application order  Feature      Integer   \n3                                           Course  Feature      Integer   \n4                       Daytime/evening attendance  Feature      Integer   \n5                           Previous qualification  Feature      Integer   \n6                   Previous qualification (grade)  Feature   Continuous   \n7                                      Nacionality  Feature      Integer   \n8                           Mother's qualification  Feature      Integer   \n9                           Father's qualification  Feature      Integer   \n10                             Mother's occupation  Feature      Integer   \n11                             Father's occupation  Feature      Integer   \n12                                 Admission grade  Feature   Continuous   \n13                                       Displaced  Feature      Integer   \n14                       Educational special needs  Feature      Integer   \n15                                          Debtor  Feature      Integer   \n16                         Tuition fees up to date  Feature      Integer   \n17                                          Gender  Feature      Integer   \n18                              Scholarship holder  Feature      Integer   \n19                               Age at enrollment  Feature      Integer   \n20                                   International  Feature      Integer   \n21             Curricular units 1st sem (credited)  Feature      Integer   \n22             Curricular units 1st sem (enrolled)  Feature      Integer   \n23          Curricular units 1st sem (evaluations)  Feature      Integer   \n24             Curricular units 1st sem (approved)  Feature      Integer   \n25                Curricular units 1st sem (grade)  Feature      Integer   \n26  Curricular units 1st sem (without evaluations)  Feature      Integer   \n27             Curricular units 2nd sem (credited)  Feature      Integer   \n28             Curricular units 2nd sem (enrolled)  Feature      Integer   \n29          Curricular units 2nd sem (evaluations)  Feature      Integer   \n30             Curricular units 2nd sem (approved)  Feature      Integer   \n31                Curricular units 2nd sem (grade)  Feature      Integer   \n32  Curricular units 2nd sem (without evaluations)  Feature      Integer   \n33                               Unemployment rate  Feature   Continuous   \n34                                  Inflation rate  Feature   Continuous   \n35                                             GDP  Feature   Continuous   \n36                                          Target   Target  Categorical   \n\n        demographic                                        description units  \\\n0    Marital Status  1 – single 2 – married 3 – widower 4 – divorce...  None   \n1              None  1 - 1st phase - general contingent 2 - Ordinan...  None   \n2              None  Application order (between 0 - first choice; a...  None   \n3              None  33 - Biofuel Production Technologies 171 - Ani...  None   \n4              None                            1 – daytime 0 - evening  None   \n5   Education Level  1 - Secondary education 2 - Higher education -...  None   \n6              None  Grade of previous qualification (between 0 and...  None   \n7       Nationality  1 - Portuguese; 2 - German; 6 - Spanish; 11 - ...  None   \n8   Education Level  1 - Secondary Education - 12th Year of Schooli...  None   \n9   Education Level  1 - Secondary Education - 12th Year of Schooli...  None   \n10       Occupation  0 - Student 1 - Representatives of the Legisla...  None   \n11       Occupation  0 - Student 1 - Representatives of the Legisla...  None   \n12             None                Admission grade (between 0 and 200)  None   \n13             None                                     1 – yes 0 – no  None   \n14             None                                     1 – yes 0 – no  None   \n15             None                                     1 – yes 0 – no  None   \n16             None                                     1 – yes 0 – no  None   \n17           Gender                                1 – male 0 – female  None   \n18             None                                     1 – yes 0 – no  None   \n19              Age                       Age of studend at enrollment  None   \n20             None                                     1 – yes 0 – no  None   \n21             None  Number of curricular units credited in the 1st...  None   \n22             None  Number of curricular units enrolled in the 1st...  None   \n23             None  Number of evaluations to curricular units in t...  None   \n24             None  Number of curricular units approved in the 1st...  None   \n25             None  Grade average in the 1st semester (between 0 a...  None   \n26             None  Number of curricular units without evalutions ...  None   \n27             None  Number of curricular units credited in the 2nd...  None   \n28             None  Number of curricular units enrolled in the 2nd...  None   \n29             None  Number of evaluations to curricular units in t...  None   \n30             None  Number of curricular units approved in the 2nd...  None   \n31             None  Grade average in the 2nd semester (between 0 a...  None   \n32             None  Number of curricular units without evalutions ...  None   \n33             None                              Unemployment rate (%)  None   \n34             None                                 Inflation rate (%)  None   \n35             None                                                GDP  None   \n36             None  Target. The problem is formulated as a three c...  None   \n\n   missing_values  \n0              no  \n1              no  \n2              no  \n3              no  \n4              no  \n5              no  \n6              no  \n7              no  \n8              no  \n9              no  \n10             no  \n11             no  \n12             no  \n13             no  \n14             no  \n15             no  \n16             no  \n17             no  \n18             no  \n19             no  \n20             no  \n21             no  \n22             no  \n23             no  \n24             no  \n25             no  \n26             no  \n27             no  \n28             no  \n29             no  \n30             no  \n31             no  \n32             no  \n33             no  \n34             no  \n35             no  \n36             no  \n\n\nNota Código tomado del apartado para Python del proveedor de datos\n\n\nConversión de estados del Target\n\nImportar pendiente\n\n\nCode\nfrom sklearn.model_selection import train_test_split\n\n\n\n\nConvertir tres estados en dos estados\n\n\nCode\n# data (as pandas dataframes) \nX = predict_students_dropout_and_academic_success.data.features \ny_original = predict_students_dropout_and_academic_success.data.targets \n\n\n# Mostramos estado Original\nprint(\"Información del dataset:\")\nprint(f\"X shape: {X.shape}\")\nprint(f\"y shape: {y_original.shape}\")\nprint(f\"Clases originales en y: {y_original['Target'].unique()}\")\n\n\n# Convertir estados en valores de 0 o 1\ny = y_original['Target'].map({'Dropout': 0, 'Enrolled': 1, 'Graduate': 1})\n\n\n## borrar print(f\"Clases binarias en y: {y.unique()}\")\n## borrar print(f\"Distribución de clases: {y.value_counts()}\")\n\n\nprint(\"\\nValores para y:\")\nprint(y.head(3))\n\n\nprint(\"\\nValores para X:\")\nprint(X.head(3))\n\n\nInformación del dataset:\nX shape: (4424, 36)\ny shape: (4424, 1)\nClases originales en y: ['Dropout' 'Graduate' 'Enrolled']\n\nValores para y:\n0    0\n1    1\n2    0\nName: Target, dtype: int64\n\nValores para X:\n   Marital Status  Application mode  Application order  Course  \\\n0               1                17                  5     171   \n1               1                15                  1    9254   \n2               1                 1                  5    9070   \n\n   Daytime/evening attendance  Previous qualification  \\\n0                           1                       1   \n1                           1                       1   \n2                           1                       1   \n\n   Previous qualification (grade)  Nacionality  Mother's qualification  \\\n0                           122.0            1                      19   \n1                           160.0            1                       1   \n2                           122.0            1                      37   \n\n   Father's qualification  ...  \\\n0                      12  ...   \n1                       3  ...   \n2                      37  ...   \n\n   Curricular units 1st sem (without evaluations)  \\\n0                                               0   \n1                                               0   \n2                                               0   \n\n   Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n0                                    0                                    0   \n1                                    0                                    6   \n2                                    0                                    6   \n\n   Curricular units 2nd sem (evaluations)  \\\n0                                       0   \n1                                       6   \n2                                       0   \n\n   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n0                                    0                          0.000000   \n1                                    6                         13.666667   \n2                                    0                          0.000000   \n\n   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n0                                               0               10.8   \n1                                               0               13.9   \n2                                               0               10.8   \n\n   Inflation rate   GDP  \n0             1.4  1.74  \n1            -0.3  0.79  \n2             1.4  1.74  \n\n[3 rows x 36 columns]"
  },
  {
    "objectID": "index.html#clasificación-sin-pipeline",
    "href": "index.html#clasificación-sin-pipeline",
    "title": "Aprendizaje Supervisado",
    "section": "Clasificación sin pipeline",
    "text": "Clasificación sin pipeline\nSe usa con pasos manuales separados\n\nSplit de datos para entrenamiento y prueba (como en tu Actividad 5)\n\n\nCode\nX_train, X_test, y_train, y_test = train_test_split(\n\n\n    X, ## Data \n    y, ## Target\n    test_size=0.2, ## Entrenamiento con el 20% \n    random_state=42, ## La división cambia cada vez (aleatoria), lo que hace difícil comparar resultados o depurar, y con 42 es para obtener la misma division.\n    stratify=y ## Guarda la proporsion \n    )\n\n\nprint(f\"\\nDatos de entrenamiento: X_train={X_train.shape}, y_train={y_train.shape}\")\nprint(f\"Datos de prueba: X_test={X_test.shape}, y_test={y_test.shape}\")\n\n\n\nDatos de entrenamiento: X_train=(3539, 36), y_train=(3539,)\nDatos de prueba: X_test=(885, 36), y_test=(885,)\n\n\n\n\nImportar librerías para sklearn\n\n\nCode\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n\n\n\n\nEscalamos el modelo\n\n\nCode\n# 2. Escalar datos (manual)\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n\n\n\nEntrenamos el modelo\n\n\nCode\n# 3. Entrenar modelo\nmodel = LogisticRegression(max_iter=1000000)\nmodel.fit(X_train_scaled, y_train)\n\n\nLogisticRegression(max_iter=1000000)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LogisticRegression?Documentation for LogisticRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\npenalty \n'l2'\n\n\n\ndual \nFalse\n\n\n\ntol \n0.0001\n\n\n\nC \n1.0\n\n\n\nfit_intercept \nTrue\n\n\n\nintercept_scaling \n1\n\n\n\nclass_weight \nNone\n\n\n\nrandom_state \nNone\n\n\n\nsolver \n'lbfgs'\n\n\n\nmax_iter \n1000000\n\n\n\nmulti_class \n'deprecated'\n\n\n\nverbose \n0\n\n\n\nwarm_start \nFalse\n\n\n\nn_jobs \nNone\n\n\n\nl1_ratio \nNone\n\n\n\n\n            \n        \n    \n\n\n\n\nSe levanta la predicción del modelo\n\n\nCode\n# 4. Predecir y evaluar\ny_pred = model.predict(X_test_scaled)\n\n\n\n\nSe hace la evaluación del modelo\n\n\nCode\naccuracy = accuracy_score(y_test, y_pred)\nprecciion=precision_score(y_test, y_pred)\nrecal=recall_score(y_test, y_pred)\nf1= f1_score(y_test, y_pred)\n\n\nprint(f\"Accuracy: {accuracy}\")\nprint(f\"Precciion: {precciion}\")\nprint(f\"Recal score: {recal}\")\nprint(f\"F1: {f1_score}\")\n\n\nAccuracy: 0.880225988700565\nPrecciion: 0.8813559322033898\nRecal score: 0.9517470881863561\nF1: &lt;function f1_score at 0x72e8e71c5300&gt;\n\n\n\n\nSe Grafica de predictibilidad\n\n\nCode\nConfusionMatrixDisplay.from_predictions(y_test,y_pred)"
  },
  {
    "objectID": "index.html#regresión-predicción-de-edad-del-estudiante",
    "href": "index.html#regresión-predicción-de-edad-del-estudiante",
    "title": "Aprendizaje Supervisado",
    "section": "Regresión: Predicción de Edad del Estudiante",
    "text": "Regresión: Predicción de Edad del Estudiante\n\nObtención de datos para regresión\nUso el mismo dataset, pero ahora predeciremos la edad (variable continua) en lugar de la clase binaria.\n\n\nImportar librerías para sklearn\n\n\nCode\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n\n\n\nTomo las datos y el Target\n\n\nCode\ny_reg = X['Age at enrollment']\nX_reg = X.drop('Age at enrollment', axis=1)\n\n\n\n\nSplit de datos para regresión\n\n\nCode\nfrom sklearn.model_selection import train_test_split\n\nX_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n\n    X_reg, y_reg, test_size=0.2, random_state=42\n)\n\nprint(f\"Datos de regresión - Train: {X_train_reg.shape}, Test: {X_test_reg.shape}\")\n\n\nDatos de regresión - Train: (3539, 35), Test: (885, 35)\n\n\n\n\nEntrenamos el modelo\n\n\nCode\n# Crear y entrenar modelo\nreg_model = LinearRegression()\nreg_model.fit(X_train_reg, y_train_reg)\n\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.LinearRegression?Documentation for LinearRegressioniFitted\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nTrue\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\n\n\nSe levanta la predicción del modelo\n\n\nCode\n# Hacer predicción\ny_pred_reg = reg_model.predict(X_test_reg)\n\n\n\n\nCode\n# Evaluar\nmse = mean_squared_error(y_test_reg, y_pred_reg)\nr2 = r2_score(y_test_reg, y_pred_reg)\n\nprint(f\"MSE (Error cuadrático medio): {mse:.2f}\")\nprint(f\"R² (Coeficiente de determinación): {r2:.2f}\")\n\n\nMSE (Error cuadrático medio): 32.16\nR² (Coeficiente de determinación): 0.52\n\n\n\n\nGráfico de Regresión\n\n\nCode\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test_reg, y_pred_reg, alpha=0.7)\nplt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\nplt.xlabel('Edad Real')\nplt.ylabel('Edad Predicha')\nplt.title('Regresión: Edad Real vs Predicha')\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "index.html#clasificación-con-pipeline",
    "href": "index.html#clasificación-con-pipeline",
    "title": "Aprendizaje Supervisado",
    "section": "Clasificación con pipeline",
    "text": "Clasificación con pipeline\n\nSplit de datos para entrenamiento y prueba (como en tu Actividad 5)\n\n\nCode\nX_train_pipe, X_test_pipe, y_train_pipe, y_test_pipe = train_test_split(\n\n\n    X, ## Data \n    y, ## Target\n    test_size=0.2, ## Entrenamiento con el 20% \n    random_state=42, ## La división cambia cada vez (aleatoria), lo que hace difícil comparar resultados o depurar, y con 42 es para obtener la misma división.\n    stratify=y ## Guarda la proporción \n    )\n\n\nprint(f\"\\nDatos de entrenamiento: X_train={X_train_pipe.shape}, y_train={y_train_pipe.shape}\")\nprint(f\"Datos de prueba: X_test={X_test_pipe.shape}, y_test={y_test_pipe.shape}\")\n\n\n\nDatos de entrenamiento: X_train=(3539, 36), y_train=(3539,)\nDatos de prueba: X_test=(885, 36), y_test=(885,)\n\n\n\n\nImportar librerías para sklearn\n\n\nCode\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\n\n\n\n\nCrear pipeline: escalado y modelo\n\n\nCode\npipeline = Pipeline([\n    ('scaler', StandardScaler()),  # Paso 1: Escalar\n    ('classifier', LogisticRegression(max_iter=1000000))  # Paso 2: Modelo\n])\n\n\n\n\nEntrenamos el modelo\n\n\nCode\n# Entrenar pipeline (escala y entrena automáticamente)\npipeline.fit(X_train_pipe, y_train_pipe)\n\n\nPipeline(steps=[('scaler', StandardScaler()),\n                ('classifier', LogisticRegression(max_iter=1000000))])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Pipeline?Documentation for PipelineiFitted\n        \n            \n                Parameters\n                \n\n\n\n\nsteps \n[('scaler', ...), ('classifier', ...)]\n\n\n\ntransform_input \nNone\n\n\n\nmemory \nNone\n\n\n\nverbose \nFalse\n\n\n\n\n            \n        \n    StandardScaler?Documentation for StandardScaler\n        \n            \n                Parameters\n                \n\n\n\n\ncopy \nTrue\n\n\n\nwith_mean \nTrue\n\n\n\nwith_std \nTrue\n\n\n\n\n            \n        \n    LogisticRegression?Documentation for LogisticRegression\n        \n            \n                Parameters\n                \n\n\n\n\npenalty \n'l2'\n\n\n\ndual \nFalse\n\n\n\ntol \n0.0001\n\n\n\nC \n1.0\n\n\n\nfit_intercept \nTrue\n\n\n\nintercept_scaling \n1\n\n\n\nclass_weight \nNone\n\n\n\nrandom_state \nNone\n\n\n\nsolver \n'lbfgs'\n\n\n\nmax_iter \n1000000\n\n\n\nmulti_class \n'deprecated'\n\n\n\nverbose \n0\n\n\n\nwarm_start \nFalse\n\n\n\nn_jobs \nNone\n\n\n\nl1_ratio \nNone\n\n\n\n\n            \n        \n    \n\n\n\n\nSe levanta la prediccion del modelo\n\n\nCode\n# Predecir (escala y predice automáticamente)\ny_pred_pipe = pipeline.predict(X_test_pipe)\n\n\n\n\nSe hace la evaluación del model\n\n\nCode\naccuracy_pipe = accuracy_score(y_test_pipe, y_pred_pipe)\nprecciion_pipe=precision_score(y_test_pipe, y_pred_pipe)\nrecal_pipe=recall_score(y_test_pipe, y_pred_pipe)\nf1_pipe= f1_score(y_test_pipe, y_pred_pipe)\n\n\nprint(f\"Accuracy: {accuracy_pipe}\")\nprint(f\"Precciion: {precciion_pipe}\")\nprint(f\"Recal score: {recal_pipe}\")\nprint(f\"F1: {f1_pipe}\")\n\n\nAccuracy: 0.880225988700565\nPrecciion: 0.8813559322033898\nRecal score: 0.9517470881863561\nF1: 0.9152\n\n\n\n\nSe Grafica de predictibilidad\n\n\nCode\nConfusionMatrixDisplay.from_predictions(y_test_pipe,y_pred_pipe)"
  },
  {
    "objectID": "index.html#regresión-predicción-de-edad-del-estudiante-con-pipeline",
    "href": "index.html#regresión-predicción-de-edad-del-estudiante-con-pipeline",
    "title": "Aprendizaje Supervisado",
    "section": "Regresión: Predicción de Edad del Estudiante con Pipeline",
    "text": "Regresión: Predicción de Edad del Estudiante con Pipeline\n\nImportar librerías para sklearn\n\n\nCode\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n\n\n\nCrear el pipeline: ecalando y modelo\n\n\nCode\n# Crear pipeline para regresión\npipeline_reg = Pipeline([\n    ('scaler', StandardScaler()),\n    ('regressor', LinearRegression())\n])\n\n\n\n\nEntrenamiento del modelo\n\n\nCode\n# Entrenar\npipeline_reg.fit(X_train_reg, y_train_reg)\n\n\nPipeline(steps=[('scaler', StandardScaler()),\n                ('regressor', LinearRegression())])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.Pipeline?Documentation for PipelineiFitted\n        \n            \n                Parameters\n                \n\n\n\n\nsteps \n[('scaler', ...), ('regressor', ...)]\n\n\n\ntransform_input \nNone\n\n\n\nmemory \nNone\n\n\n\nverbose \nFalse\n\n\n\n\n            \n        \n    StandardScaler?Documentation for StandardScaler\n        \n            \n                Parameters\n                \n\n\n\n\ncopy \nTrue\n\n\n\nwith_mean \nTrue\n\n\n\nwith_std \nTrue\n\n\n\n\n            \n        \n    LinearRegression?Documentation for LinearRegression\n        \n            \n                Parameters\n                \n\n\n\n\nfit_intercept \nTrue\n\n\n\ncopy_X \nTrue\n\n\n\ntol \n1e-06\n\n\n\nn_jobs \nNone\n\n\n\npositive \nFalse\n\n\n\n\n            \n        \n    \n\n\n\n\nSe levanta la predicción del modelo\n\n\nCode\n# Predecir\ny_pred_reg = pipeline_reg.predict(X_test_reg)\n\n\n\n\nSe hace la evolución del modelo\n\n\nCode\n# Evaluar\nmse = mean_squared_error(y_test_reg, y_pred_reg)\nr2 = r2_score(y_test_reg, y_pred_reg)\n\nprint(f\"MSE (Error cuadrático medio): {mse:.2f}\")\nprint(f\"R² (Coeficiente de determinación): {r2:.2f}\")\n\n\nMSE (Error cuadrático medio): 32.16\nR² (Coeficiente de determinación): 0.52\n\n\n\n\nGráfico de Regresión\n\n\nCode\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 6))\nplt.scatter(y_test_reg, y_pred_reg, alpha=0.7)\nplt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)\nplt.xlabel('Edad Real')\nplt.ylabel('Edad Predicha')\nplt.title('Regresión: Edad Real vs Predicha')\nplt.grid(True)\nplt.show()"
  },
  {
    "objectID": "index.html#conclusiones",
    "href": "index.html#conclusiones",
    "title": "Aprendizaje Supervisado",
    "section": "Conclusiones",
    "text": "Conclusiones\n\nConclusiones de Clasificación\n\nAccuracy: Con 88% la clasificación es correcta para la mayoría de los casos.\nPrecisión: Con 88.14% indica que es alta y da confiabilidad y limita falsos positivos\nRecall: de 95.17% el modelo si detecta los estudiantes que abandonan.\nF1 Balanceado: 91.52% la media armónica entre Precisión y Recall es alta, por lo que es balanceado el nivel de abandonos y las falsas alertas.\n\nPara ambos métodos usamos el mismo algoritmo de clasificación, solo que el pipeline es una buena práctica, ya que se crea con menos pasos y la respuesta es idéntica.\n\n\nConclusiones de Regresión\n\nMSE: El valor obtenido indica el promedio de los errores al cuadrado entre las edades reales y predichas. Un MSE bajo de 32.16 indica que se tiene un buen ajuste.\nR 2: El valor de R2 muestra qué porcentaje de la variabilidad en la edad es explicada por el modelo. Un R² cercano a 1 indica un buen ajuste, mientras que valores bajos sugieren que otras variables o modelos más complejos podrían mejorar la predicción.\nComparación con Pipeline: Al igual que en clasificación, usar pipeline en regresión evita data leakage(también conocida como fuga de datos) y facilita el proceso, con resultados similares al método por pasos.\n\n\nNota: Como desarrollador veo que al usar pipeline se puede automatizar nuevos escenarios, pues en una sola funcion se pudiese implemantar otras funcionalidades y ejecutar en forma masivas para tener resultados automaticos"
  }
]