# Aprendizaje Supervisado

Autor: Omar Velez - omar.velez@yachaytech.edu.ec

## Obtención de la data:


Para la obtención de la DataFrame se obtiene la predicción de deserción escolar de la: Irvine, Universidad de California (UCI) [Ver](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success)


El DataFrame original en su target tiene los siguientes estados: 'Dropout', 'Enrolled', 'Graduate'. Y hay que reducirlos a Enrolled y Graduate para podemos usar como 0 y 1 respectivamente.


### Desarrollo


#### Se instala la librería del DataFrame
```{python}
!pip install ucimlrepo
```


#### Válido si está correctamente instalada la librería
```{python}
import ucimlrepo
print("ucimlrepo instalado correctamente")
```


#### Se obtiene el dataFrame desde la url de la UCI
```{python}


from ucimlrepo import fetch_ucirepo 
  
# fetch dataset 697
predict_students_dropout_and_academic_success = fetch_ucirepo(id=697) 
  
# data (as pandas dataframes) 
X = predict_students_dropout_and_academic_success.data.features 
y = predict_students_dropout_and_academic_success.data.targets 
  
# metadata 
print(predict_students_dropout_and_academic_success.metadata) 
  
# variable information 
print(predict_students_dropout_and_academic_success.variables) 


```
**Nota**
Código tomado del apartado para Python del proveedor de datos


#### Conversión de estados del Target


##### Importar pendiente


```{python}
from sklearn.model_selection import train_test_split
```


##### Convertir tres estados en dos estados


```{python}


# data (as pandas dataframes)  [Ov] -> no se uso pandas 
X = predict_students_dropout_and_academic_success.data.features 
y_original = predict_students_dropout_and_academic_success.data.targets 


# Mostramos estado Original
print("Información del dataset:")
print(f"X shape: {X.shape}")
print(f"y shape: {y_original.shape}")
print(f"Clases originales en y: {y_original['Target'].unique()}")


# Convertir estados en valores de 0 o 1
y = y_original['Target'].map({'Dropout': 0, 'Enrolled': 1, 'Graduate': 1})


## borrar print(f"Clases binarias en y: {y.unique()}")
## borrar print(f"Distribución de clases: {y.value_counts()}")


print("\nValores para y:")
print(y.head(3))


print("\nValores para X:")
print(X.head(3))


```


## Clasificación sin pipeline


Se usa con pasos manuales separados


### Split de datos para entrenamiento y prueba (como en tu Actividad 5)


```{python}
X_train, X_test, y_train, y_test = train_test_split(


    X, ## Data 
    y, ## Target
    test_size=0.2, ## Entrenamiento con el 20% 
    random_state=42, ## La división cambia cada vez (aleatoria), lo que hace difícil comparar resultados o depurar, y con 42 es para obtener la misma division.
    stratify=y ## Guarda la proporsion 
    )


print(f"\nDatos de entrenamiento: X_train={X_train.shape}, y_train={y_train.shape}")
print(f"Datos de prueba: X_test={X_test.shape}, y_test={y_test.shape}")
```




### Importar librerías para sklearn


```{python}
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay
```


### Escalamos el modelo
```{python}


scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


```


### Entrenamos el modelo
```{python}
model = LogisticRegression(max_iter=1000000)
model.fit(X_train_scaled, y_train)
```


### Se levanta la predicción del modelo


```{python}
y_pred = model.predict(X_test_scaled)


```


### Se hace la evaluación del modelo
```{python}
accuracy = accuracy_score(y_test, y_pred)
precciion=precision_score(y_test, y_pred)
recal=recall_score(y_test, y_pred)
f1= f1_score(y_test, y_pred)


print(f"Accuracy: {accuracy}")
print(f"Precciion: {precciion}")
print(f"Recal score: {recal}")
print(f"F1: {f1_score}")
```


### Se Grafica de predictibilidad
```{python}
ConfusionMatrixDisplay.from_predictions(y_test,y_pred)
```

## Regresión: Predicción de Edad del Estudiante

### Obtención de datos para regresión

Uso el mismo dataset, pero ahora predeciremos la **edad** (variable continua) en lugar de la clase binaria.


### Importar librerías para sklearn
```{python}
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
```

### Tomo las datos y el Target
```{python}
y_reg = X['Age at enrollment']
X_reg = X.drop('Age at enrollment', axis=1)
```

### Split de datos para regresión

```{python}
from sklearn.model_selection import train_test_split

X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(

    X_reg, y_reg, test_size=0.2, random_state=42
)

print(f"Datos de regresión - Train: {X_train_reg.shape}, Test: {X_test_reg.shape}")
```
### Entrenamos el modelo

```{python}
# Crear y entrenar modelo
reg_model = LinearRegression()
reg_model.fit(X_train_reg, y_train_reg)
```

### Se levanta la predicción del modelo

```{python}
# Hacer predicción 
y_pred_reg = reg_model.predict(X_test_reg)
```

```{python}

# Evaluar
mse = mean_squared_error(y_test_reg, y_pred_reg)
r2 = r2_score(y_test_reg, y_pred_reg)

print(f"MSE (Error cuadrático medio): {mse:.2f}")
print(f"R² (Coeficiente de determinación): {r2:.2f}")
```

### Gráfico de Regresión

```{python}
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.scatter(y_test_reg, y_pred_reg, alpha=0.7)
plt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)
plt.xlabel('Edad Real')
plt.ylabel('Edad Predicha')
plt.title('Regresión: Edad Real vs Predicha')
plt.grid(True)
plt.show()
```


## Clasificación con pipeline


### Split de datos para entrenamiento y prueba (como en tu Actividad 5)


```{python}
X_train_pipe, X_test_pipe, y_train_pipe, y_test_pipe = train_test_split(


    X, ## Data 
    y, ## Target
    test_size=0.2, ## Entrenamiento con el 20% 
    random_state=42, ## La división cambia cada vez (aleatoria), lo que hace difícil comparar resultados o depurar, y con 42 es para obtener la misma división.
    stratify=y ## Guarda la proporción 
    )


print(f"\nDatos de entrenamiento: X_train={X_train_pipe.shape}, y_train={y_train_pipe.shape}")
print(f"Datos de prueba: X_test={X_test_pipe.shape}, y_test={y_test_pipe.shape}")
```


### Importar librerías para sklearn


```{python}
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
```

### Crear pipeline: escalado y modelo  
```{python}
pipeline = Pipeline([
    ('scaler', StandardScaler()),  # Paso 1: Escalar
    ('classifier', LogisticRegression(max_iter=1000000))  # Paso 2: Modelo
])
```
### Entrenamos el modelo
```{python}
# Entrenar pipeline :)
pipeline.fit(X_train_pipe, y_train_pipe)
```


### Se levanta la prediccion del modelo
```{python}
# Predecir 
y_pred_pipe = pipeline.predict(X_test_pipe)


```


### Se hace la evaluación del model


```{python}
accuracy_pipe = accuracy_score(y_test_pipe, y_pred_pipe)
precciion_pipe=precision_score(y_test_pipe, y_pred_pipe)
recal_pipe=recall_score(y_test_pipe, y_pred_pipe)
f1_pipe= f1_score(y_test_pipe, y_pred_pipe)


print(f"Accuracy: {accuracy_pipe}")
print(f"Precciion: {precciion_pipe}")
print(f"Recal score: {recal_pipe}")
print(f"F1: {f1_pipe}")


```




### Se Grafica de predictibilidad
```{python}
ConfusionMatrixDisplay.from_predictions(y_test_pipe,y_pred_pipe)
```


## Regresión: Predicción de Edad del Estudiante con Pipeline

### Importar librerías para sklearn

```{python}
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

```
### Crear el pipeline: ecalando y modelo
```{python}
# Crear pipeline para regresión
pipeline_reg = Pipeline([
    ('scaler', StandardScaler()),
    ('regressor', LinearRegression())
])

```
### Entrenamiento del modelo
```{python}

# Entrenar
pipeline_reg.fit(X_train_reg, y_train_reg)

```
### Se levanta la predicción del modelo
```{python}

# Predecir
y_pred_reg = pipeline_reg.predict(X_test_reg)

```
### Se hace la evolución del modelo
```{python}

# Evaluar <- estudiar esto se te olivida
mse = mean_squared_error(y_test_reg, y_pred_reg)
r2 = r2_score(y_test_reg, y_pred_reg)

print(f"MSE (Error cuadrático medio): {mse:.2f}")
print(f"R² (Coeficiente de determinación): {r2:.2f}")
```

### Gráfico de Regresión

```{python}
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.scatter(y_test_reg, y_pred_reg, alpha=0.7)
plt.plot([y_test_reg.min(), y_test_reg.max()], [y_test_reg.min(), y_test_reg.max()], 'r--', lw=2)
plt.xlabel('Edad Real')
plt.ylabel('Edad Predicha')
plt.title('Regresión: Edad Real vs Predicha')
plt.grid(True)
plt.show()
```

## Conclusiones 

### Conclusiones de Clasificación

- **Accuracy**: Con 88% la clasificación es correcta para la mayoría de los casos.

- **Precisión**: Con 88.14% indica que es alta y da confiabilidad y limita falsos positivos

- **Recall**: de 95.17% el modelo si detecta los estudiantes que abandonan.

- **F1 Balanceado**: 91.52% la media armónica entre Precisión y Recall es alta, por lo que es balanceado el nivel de abandonos y las falsas alertas.

Para ambos métodos usamos el mismo algoritmo de clasificación, solo que el pipeline es una buena práctica, ya que se crea con menos pasos y la respuesta es idéntica.

### Conclusiones de Regresión

- **MSE**: El valor obtenido indica el promedio de los errores al cuadrado entre las edades reales y predichas. Un MSE bajo de 32.16 indica que se tiene un buen ajuste.

- **R 2**: El valor de R2 muestra qué porcentaje de la variabilidad en la edad SI es explicada por el modelo.

- **Comparación con Pipeline**: Al igual que en clasificación, usar pipeline en regresión evita data leakage(también conocida como fuga de datos) y facilita el proceso, con resultados similares al método por pasos.

--- 

*Nota*: Como desarrollador veo que al usar pipeline se puede automatizar nuevos escenarios, pues en una sola funcion se pudiese implemantar otras funcionalidades y ejecutar en forma masivas para tener resultados automaticos

